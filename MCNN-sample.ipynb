{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Multi-Column CNN (MCNN) for Crowd Counting\n",
    "Este notebook implementa un modelo MCNN para conteo de multitudes usando el dataset ShanghaiTech."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, Reshape, Concatenate\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "import os \n",
    "import cv2\n",
    "import keras.backend as K\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Configuración del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar el dataset (A o B)\n",
    "dataset = 'A'  # Cambiar a 'B' si es necesario\n",
    "print('dataset:', dataset)\n",
    "\n",
    "# Rutas de los datos\n",
    "train_path = './data/formatted_trainval/shanghaitech_part_' + dataset + '_patches_9/train/'\n",
    "train_den_path = './data/formatted_trainval/shanghaitech_part_' + dataset + '_patches_9/train_den/'\n",
    "val_path = './data/formatted_trainval/shanghaitech_part_' + dataset + '_patches_9/val/'\n",
    "val_den_path = './data/formatted_trainval/shanghaitech_part_' + dataset + '_patches_9/val_den/'\n",
    "img_path = './data/original/shanghaitech/part_' + dataset + '_final/test_data/images/'\n",
    "den_path = './data/original/shanghaitech/part_' + dataset + '_final/test_data/ground_truth_csv/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Funciones de preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_pre_train():\n",
    "    print('loading data from dataset ', dataset, '...')\n",
    "    train_img_names = os.listdir(train_path)\n",
    "    img_num = len(train_img_names)\n",
    "\n",
    "    train_data = []\n",
    "    for i in range(img_num):\n",
    "        if i % 100 == 0:\n",
    "            print(i, '/', img_num)\n",
    "        name = train_img_names[i]\n",
    "        #print(name + '****************************')\n",
    "        img = cv2.imread(train_path + name, 0)\n",
    "        img = np.array(img)\n",
    "        img = (img - 127.5) / 128\n",
    "        #print(img.shape)\n",
    "        den = np.loadtxt(open(train_den_path + name[:-4] + '.csv'), delimiter = \",\")\n",
    "        den_quarter = np.zeros((int(den.shape[0] / 4), int(den.shape[1] / 4)))\n",
    "        #print(den_quarter.shape)\n",
    "        for i in range(len(den_quarter)):\n",
    "            for j in range(len(den_quarter[0])):\n",
    "                for p in range(4):\n",
    "                    for q in range(4):\n",
    "                        den_quarter[i][j] += den[i * 4 + p][j * 4 + q]\n",
    "        train_data.append([img, den_quarter])\n",
    "\n",
    "    print('load data finished.')\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_pre_test():\n",
    "    print('loading test data from dataset', dataset, '...')\n",
    "    img_names = os.listdir(img_path)\n",
    "    img_num = len(img_names)\n",
    "\n",
    "    data = []\n",
    "    for i in range(img_num):\n",
    "        if i % 50 == 0:\n",
    "            print(i, '/', img_num)\n",
    "        name = 'IMG_' + str(i + 1) + '.jpg'\n",
    "        #print(name + '****************************')\n",
    "        img = cv2.imread(img_path + name, 0)\n",
    "        img = np.array(img)\n",
    "        img = (img - 127.5) / 128\n",
    "        #print(img.shape)\n",
    "        den = np.loadtxt(open(den_path + name[:-4] + '.csv'), delimiter = \",\")\n",
    "        den_quarter = np.zeros((int(den.shape[0] / 4), int(den.shape[1] / 4)))\n",
    "        #print(den_quarter.shape)\n",
    "        for i in range(len(den_quarter)):\n",
    "            for j in range(len(den_quarter[0])):\n",
    "                for p in range(4):\n",
    "                    for q in range(4):\n",
    "                        den_quarter[i][j] += den[i * 4 + p][j * 4 + q]\n",
    "        #print(den.shape)\n",
    "        data.append([img, den_quarter])\n",
    "            \n",
    "    print('load data finished.')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Carga y preparación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos de entrenamiento y prueba\n",
    "data = data_pre_train()\n",
    "data_test = data_pre_test()\n",
    "np.random.shuffle(data)\n",
    "\n",
    "# Preparar datos de entrenamiento\n",
    "x_train = []\n",
    "y_train = []\n",
    "for d in data:\n",
    "    x_train.append(np.reshape(d[0], (d[0].shape[0], d[0].shape[1], 1)))\n",
    "    y_train.append(np.reshape(d[1], (d[1].shape[0], d[1].shape[1], 1)))\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "# Preparar datos de prueba\n",
    "x_test = []\n",
    "y_test = []\n",
    "for d in data_test:\n",
    "    x_test.append(np.reshape(d[0], (d[0].shape[0], d[0].shape[1], 1)))\n",
    "    y_test.append(np.reshape(d[1], (d[1].shape[0], d[1].shape[1], 1)))\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print('Forma de x_train:', x_train.shape)\n",
    "print('Forma de y_train:', y_train.shape)\n",
    "print('Forma de x_test:', x_test.shape)\n",
    "print('Forma de y_test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Métricas personalizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maaae(y_true, y_pred):\n",
    "    return abs(K.sum(y_true) - K.sum(y_pred))\n",
    "\n",
    "def mssse(y_true, y_pred):\n",
    "    return (K.sum(y_true) - K.sum(y_pred)) * (K.sum(y_true) - K.sum(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Arquitectura del modelo MCNN\n",
    "El modelo Multi-Column CNN utiliza tres ramas con diferentes tamaños de filtro para capturar características a diferentes escalas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de la arquitectura del modelo\n",
    "inputs = Input(shape = (None, None, 1))\n",
    "\n",
    "# Rama media (conv_m) - filtros medianos\n",
    "conv_m = Conv2D(20, (7, 7), padding = 'same', activation = 'relu')(inputs)\n",
    "conv_m = MaxPooling2D(pool_size = (2, 2))(conv_m)\n",
    "conv_m = Conv2D(40, (5, 5), padding = 'same', activation = 'relu')(conv_m)\n",
    "conv_m = MaxPooling2D(pool_size = (2, 2))(conv_m)\n",
    "conv_m = Conv2D(20, (5, 5), padding = 'same', activation = 'relu')(conv_m)\n",
    "conv_m = Conv2D(10, (5, 5), padding = 'same', activation = 'relu')(conv_m)\n",
    "\n",
    "# Rama pequeña (conv_s) - filtros pequeños\n",
    "conv_s = Conv2D(24, (5, 5), padding = 'same', activation = 'relu')(inputs)\n",
    "conv_s = MaxPooling2D(pool_size = (2, 2))(conv_s)\n",
    "conv_s = Conv2D(48, (3, 3), padding = 'same', activation = 'relu')(conv_s)\n",
    "conv_s = MaxPooling2D(pool_size = (2, 2))(conv_s)\n",
    "conv_s = Conv2D(24, (3, 3), padding = 'same', activation = 'relu')(conv_s)\n",
    "conv_s = Conv2D(12, (3, 3), padding = 'same', activation = 'relu')(conv_s)\n",
    "\n",
    "# Rama grande (conv_l) - filtros grandes\n",
    "conv_l = Conv2D(16, (9, 9), padding = 'same', activation = 'relu')(inputs)\n",
    "conv_l = MaxPooling2D(pool_size = (2, 2))(conv_l)\n",
    "conv_l = Conv2D(32, (7, 7), padding = 'same', activation = 'relu')(conv_l)\n",
    "conv_l = MaxPooling2D(pool_size = (2, 2))(conv_l)\n",
    "conv_l = Conv2D(16, (7, 7), padding = 'same', activation = 'relu')(conv_l)\n",
    "conv_l = Conv2D(8, (7, 7), padding = 'same', activation = 'relu')(conv_l)\n",
    "\n",
    "# Concatenación de las tres ramas\n",
    "conv_merge = Concatenate(axis = 3)([conv_m, conv_s, conv_l])\n",
    "result = Conv2D(1, (1, 1), padding = 'same')(conv_merge)\n",
    "\n",
    "# Crear el modelo\n",
    "model = Model(inputs = inputs, outputs = result)\n",
    "\n",
    "# Mostrar resumen del modelo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Compilación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar el modelo\n",
    "adam = Adam(lr = 1e-4)\n",
    "model.compile(loss = 'mse', optimizer = adam, metrics = [maaae, mssse])\n",
    "\n",
    "print('Modelo compilado exitosamente')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables para rastrear el mejor rendimiento\n",
    "best_mae = 10000\n",
    "best_mae_mse = 10000\n",
    "best_mse = 10000\n",
    "best_mse_mae = 10000\n",
    "\n",
    "# Bucle de entrenamiento\n",
    "for i in range(200):\n",
    "    print(f'\\n=== Época {i+1}/200 ===')\n",
    "    \n",
    "    # Entrenar el modelo\n",
    "    model.fit(x_train, y_train, epochs = 3, batch_size = 1, validation_split = 0.2)\n",
    "\n",
    "    # Evaluar en el conjunto de prueba\n",
    "    score = model.evaluate(x_test, y_test, batch_size = 1)\n",
    "    score[2] = math.sqrt(score[2])  # Convertir MSE a RMSE\n",
    "    \n",
    "    print(f'Loss: {score[0]:.4f}, MAE: {score[1]:.4f}, RMSE: {score[2]:.4f}')\n",
    "    \n",
    "    # Guardar el mejor modelo basado en MAE\n",
    "    if score[1] < best_mae:\n",
    "        best_mae = score[1]\n",
    "        best_mae_mse = score[2]\n",
    "        \n",
    "        json_string = model.to_json()\n",
    "        open('model.json', 'w').write(json_string)\n",
    "        model.save_weights('weights.h5')\n",
    "        print('¡Nuevo mejor modelo guardado!')\n",
    "        \n",
    "    # Actualizar mejor MSE\n",
    "    if score[2] < best_mse:\n",
    "        best_mse = score[2]\n",
    "        best_mse_mae = score[1]\n",
    "\n",
    "    print(f'Mejor MAE: {best_mae:.4f} (RMSE: {best_mae_mse:.4f})')\n",
    "    print(f'Mejor RMSE: {best_mse:.4f} (MAE: {best_mse_mae:.4f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Resultados finales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== ENTRENAMIENTO COMPLETADO ===')\n",
    "print(f'Mejor MAE alcanzado: {best_mae:.4f}')\n",
    "print(f'Mejor RMSE alcanzado: {best_mse:.4f}')\n",
    "print('Modelo y pesos guardados como model.json y weights.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
